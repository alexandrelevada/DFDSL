# DFDSL: Dataset Filtering and Decomposition for Supervised Learning

In supervised learning, the quality and structure of the dataset significantly impact model performance. Traditional methods often struggle with noisy, imbalanced, or complex datasets, leading to suboptimal models. In this study, we present a novel information-theoretic method for labeled graph node filtering and decomposition. Our method views a labeled graph as the outcome of a Potts Markov random field model. The metric and curvature tensors of the parametric space of a statistical model are connected to the first and second order Fisher information matrices, according to information geometry. Hence, the proposed approach is able to distinguish between low and high information nodes by estimating the local shape operator, which enables the labeled graph to be divided into two interrelated set of nodes: the smooth nodes and the boundary nodes. We introduce a filtering mechanism that leverages these metrics to identify samples that can be considered as more or less informative, improving data quality. Additionally, we employ graph decomposition techniques to partition the dataset into more homogeneous subgroups, facilitating more accurate and efficient learning. Our results indicate that the subgraph induced by the low information nodes define a smooth representation of the dataset, while the subgraph induced by the high information nodes is mostly composed by samples that are close to the decision boundaries.  Our method can be an interesting tool in several machine learning tasks, as non-uniform sampling, noise reduction and data segmentation.
